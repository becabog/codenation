
from math import sqrt

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import scipy.stats as sct
import seaborn as sns
import statsmodels.api as sm
import statsmodels.stats as st
from sklearn.decomposition import PCA

from loguru import logger

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.feature_selection import RFE

# Algumas configurações para o matplotlib.
# %matplotlib inline

from IPython.core.pylabtools import figsize


figsize(12, 8)

sns.set()

fifa = pd.read_csv("data.csv")

columns_to_drop = ["Unnamed: 0", "ID", "Name", "Photo", "Nationality", "Flag",
                   "Club", "Club Logo", "Value", "Wage", "Special", "Preferred Foot",
                   "International Reputation", "Weak Foot", "Skill Moves", "Work Rate",
                   "Body Type", "Real Face", "Position", "Jersey Number", "Joined",
                   "Loaned From", "Contract Valid Until", "Height", "Weight", "LS",
                   "ST", "RS", "LW", "LF", "CF", "RF", "RW", "LAM", "CAM", "RAM", "LM",
                   "LCM", "CM", "RCM", "RM", "LWB", "LDM", "CDM", "RDM", "RWB", "LB", "LCB",
                   "CB", "RCB", "RB", "Release Clause"
]

try:
    fifa.drop(columns_to_drop, axis=1, inplace=True)
except KeyError:
    logger.warning(f"Columns already dropped")

len(fifa)-len(fifa.dropna())

q3()

# Sua análise começa aqui.
fit = pca.fit(fifa.dropna())

def q1():
    pca = PCA(1)
    fit = pca.fit(fifa.dropna())
    evr = pca.explained_variance_ratio_
    return float(round(evr[0],3))

def q2():
    pca = PCA(0.95)
    n_components = pca.fit_transform(fifa.dropna())
    return int(n_components.shape[1])

x = [0.87747123,  -1.24990363,  -1.3191255, -36.7341814,
     -35.55091139, -37.29814417, -28.68671182, -30.90902583,
     -42.37100061, -32.17082438, -28.86315326, -22.71193348,
     -38.36945867, -20.61407566, -22.72696734, -25.50360703,
     2.16339005, -27.96657305, -33.46004736,  -5.08943224,
     -30.21994603,   3.68803348, -36.10997302, -30.86899058,
     -22.69827634, -37.95847789, -22.40090313, -30.54859849,
     -26.64827358, -19.28162344, -34.69783578, -34.6614351,
     48.38377664,  47.60840355,  45.76793876,  44.61110193,
     49.28911284
]

def q3():
    pca = PCA(2).fit(fifa.dropna())
    result = pca.components_.dot(x).round(3)
    return tuple(result)

def q4():
    fifa.dropna(inplace = True)
    fifa_x = fifa.drop('Overall',1)
    fifa_y = fifa['Overall']
    X_train, X_test, y_train, y_test = train_test_split(fifa_x,  fifa_y, test_size = 0.2)
    sc = StandardScaler()
    X_train = ((X_train - X_train.mean())/X_train.std())
    X_test = ((X_test - X_test.mean())/X_test.std())
    linear = LinearRegression()
    model = linear.fit(X_train, y_train)
    rfe = RFE(linear, 5)
    rfe_fit = rfe.fit(X_train, y_train)
    resultado = pd.DataFrame({'colunas': X_train.columns, 
                              'bool':rfe_fit.get_support(),
                              'coeficientes': pd.Series(linear.coef_)})
    resultado_coef = resultado[resultado['bool'] == True]
    resultado_final = list(resultado_coef['colunas'])
    return resultado_final
